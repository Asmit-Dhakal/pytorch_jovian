{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUIthymtBtJ8nJIQQxt12t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asmit-Dhakal/pytorch_jovian/blob/main/02_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Linear Regression\n",
        "We'll discuss one of the foundational algorithms in machine learning: *Linear regression*. We'll create a model that predicts crop yields for apples and oranges (*target variables*) by looking at the average temperature, rainfall, and humidity (*input variables or features*) in a region. Here's the training data:\n",
        "\n",
        "![linear-regression-training-data](https://i.imgur.com/6Ujttb4.png)\n",
        "\n",
        "In a linear regression model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
        "\n",
        "```\n",
        "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
        "```\n",
        "\n",
        "Visually, it means that the yield of apples is a linear or planar function of temperature, rainfall and humidity:\n",
        "\n",
        "![linear-regression-graph](https://i.imgur.com/4DJ9f8X.png)"
      ],
      "metadata": {
        "id": "5P6waK-ZAE0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *learning* part of linear regression is to figure out a set of weights `w11, w12,... w23, b1 & b2` using the training data, to make accurate predictions for new data. The _learned_ weights will be used to predict the yields for apples and oranges in a new region using the average temperature, rainfall, and humidity for that region.\n",
        "\n",
        "We'll _train_ our model by adjusting the weights slightly many times to make better predictions, using an optimization technique called *gradient descent*. Let's begin by importing Numpy and PyTorch"
      ],
      "metadata": {
        "id": "oFK2oaKXCNPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "HxXFhWe__jpU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training data\n",
        "\n",
        "We can represent the training data using two matrices: `inputs` and `targets`, each with one row per observation, and one column per variable."
      ],
      "metadata": {
        "id": "bFK5qQwICs_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "metadata": {
        "id": "vcVbqSNSCR6_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "emkMLABjCl11"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've separated the input and target variables because we'll operate on them separately. Also, we've created numpy arrays, because this is typically how you would work with training data: read some CSV files as numpy arrays, do some processing, and then convert them to PyTorch tensors.\n",
        "\n",
        "Let's convert the arrays to PyTorch tensors."
      ],
      "metadata": {
        "id": "b1cIjVdFC1V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert inputs and targets to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycRTSUNiC14S",
        "outputId": "c03d29e0-dd0c-4aaa-801d-951240a09a14"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression model from scratch\n",
        "\n",
        "The weights and biases (`w11, w12,... w23, b1 & b2`) can also be represented as matrices, initialized as random values. The first row of `w` and the first element of `b` are used to predict the first target variable, i.e., yield of apples, and similarly, the second for oranges."
      ],
      "metadata": {
        "id": "Q5e5NjY2DGrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights and biases\n",
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3zGgOfgC57a",
        "outputId": "c93dd9be-8e82-4d37-a9cb-2c6edde55af9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.8919, -1.9891, -0.7716],\n",
            "        [-0.5837,  1.4076, -0.8793]], requires_grad=True)\n",
            "tensor([-1.2258, -0.3565], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.randn` creates a tensor with the given shape, with elements picked randomly from a [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) with mean 0 and standard deviation 1.\n",
        "\n",
        "Our *model* is simply a function that performs a matrix multiplication of the `inputs` and the weights `w` (transposed) and adds the bias `b` (replicated for each observation).\n",
        "\n",
        "![matrix-mult](https://i.imgur.com/WGXLFvA.png)\n",
        "\n",
        "We can define the model as follows:"
      ],
      "metadata": {
        "id": "lV-5Hk1uDv8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`@` represents matrix multiplication in PyTorch, and the `.t` method returns the transpose of a tensor.\n",
        "\n",
        "The matrix obtained by passing the input data into the model is a set of predictions for the target variables."
      ],
      "metadata": {
        "id": "pu5hmheAE2sW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "  return x @ w.t()+b"
      ],
      "metadata": {
        "id": "fu9GvdDyDOR2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare the predictions of our model with the actual targets."
      ],
      "metadata": {
        "id": "cUzHnziDvkug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "id": "fYegXKHlDugl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17f0f6f-da87-4ccb-bc19-414836c1b638"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-305.7774,   13.5315],\n",
            "        [-397.8046,   14.1187],\n",
            "        [-477.1054,   86.4814],\n",
            "        [-308.2738,  -31.9043],\n",
            "        [-376.7258,   32.9460]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs\n"
      ],
      "metadata": {
        "id": "dLEhsWt4uJUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3497df4-d22a-4737-86de-25fb177c1c23"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRR2LEPjRb-W",
        "outputId": "beff920a-d438-46c1-ed18-69063740129c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare the predictions of our model with the actual targets."
      ],
      "metadata": {
        "id": "53jzE4fvV3lE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see a big difference between our model's predictions and the actual targets because we've initialized our model with random weights and biases. Obviously, we can't expect a randomly initialized model to *just work*."
      ],
      "metadata": {
        "id": "lL76GDS4WBND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function\n",
        "\n",
        "Before we improve our model, we need a way to evaluate how well our model is performing. We can compare the model's predictions with the actual targets using the following method:\n",
        "\n",
        "* Calculate the difference between the two matrices (`preds` and `targets`).\n",
        "* Square all elements of the difference matrix to remove negative values.\n",
        "* Calculate the average of the elements in the resulting matrix.\n",
        "\n",
        "The result is a single number, known as the **mean squared error** (MSE)."
      ],
      "metadata": {
        "id": "8KGpgFq0WIts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE loss\n",
        "def mse(t1, t2):\n",
        "    diff = t1 - t2\n",
        "    return torch.sum(diff * diff) / diff.numel()"
      ],
      "metadata": {
        "id": "Eyxtn_CQRqq6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.sum` returns the sum of all the elements in a tensor. The `.numel` method of a tensor returns the number of elements in a tensor. Let's compute the mean squared error for the current predictions of our model."
      ],
      "metadata": {
        "id": "RZMHlR8cbfjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff=preds-targets\n",
        "diff.numel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qU1KOm7WhgV",
        "outputId": "c83ad864-f385-445d-fff9-e6b1098152db"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute loss\n",
        "loss= mse(preds,targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DOaGlNGcoXE",
        "outputId": "58dd4501-3b6f-449b-b5cd-b97e7125b46d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(107975., grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s how we can interpret the result: *On average, each element in the prediction differs from the actual target by the square root of the loss*. And that’s pretty bad, considering the numbers we are trying to predict are themselves in the range 50–200. The result is called the *loss* because it indicates how bad the model is at predicting the target variables. It represents information loss in the model: the lower the loss, the better the model."
      ],
      "metadata": {
        "id": "7Nd1EryCdd1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute gradients\n",
        "\n",
        "With PyTorch, we can automatically compute the gradient or derivative of the loss w.r.t. to the weights and biases because they have `requires_grad` set to `True`. We'll see how this is useful in just a moment."
      ],
      "metadata": {
        "id": "gjwU2QN-di2d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "evKRh4UIdYjy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}